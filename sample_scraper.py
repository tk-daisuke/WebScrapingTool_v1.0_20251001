"""
ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰
GitHubãƒˆãƒ¬ãƒ³ãƒ‰ãƒšãƒ¼ã‚¸ã‚’å¯¾è±¡ã¨ã—ã¦ã€ãƒ„ãƒ¼ãƒ«ã®ä¸»è¦æ©Ÿèƒ½ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹
"""

import configparser
import pandas as pd
import time
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import logging

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from excel_writer import ExcelWriter
from slack_notifier import MockSlackNotifier

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class GitHubTrendScraper:
    """GitHubãƒˆãƒ¬ãƒ³ãƒ‰ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’è¡Œã†ã‚µãƒ³ãƒ—ãƒ«ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.driver = None
        self.setup_driver()
    
    def setup_driver(self):
        """WebDriverã‚’è¨­å®šãƒ»èµ·å‹•ã™ã‚‹"""
        try:
            # Chrome ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¨­å®š
            chrome_options = Options()
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            
            # WebDriverManagerã‚’ä½¿ç”¨ã—ã¦ChromeDriverã‚’è‡ªå‹•ç®¡ç†
            service = Service(ChromeDriverManager().install())
            
            # WebDriverã‚’èµ·å‹•
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.implicitly_wait(10)
            
            logger.info("WebDriverãŒæ­£å¸¸ã«èµ·å‹•ã—ã¾ã—ãŸ")
            return True
            
        except Exception as e:
            logger.error(f"WebDriverã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    
    def scrape_trending_repositories(self):
        """
        GitHubãƒˆãƒ¬ãƒ³ãƒ‰ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            pd.DataFrame: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‡ãƒ¼ã‚¿
        """
        try:
            logger.info("GitHubãƒˆãƒ¬ãƒ³ãƒ‰ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã„ã¾ã™...")
            
            # GitHubãƒˆãƒ¬ãƒ³ãƒ‰ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            self.driver.get("https://github.com/trending")
            
            # ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿å®Œäº†ã‚’å¾…æ©Ÿ
            WebDriverWait(self.driver, 30).until(
                EC.presence_of_element_located((By.CLASS_NAME, "Box-row"))
            )
            
            time.sleep(3)  # è¿½åŠ ã®å¾…æ©Ÿ
            
            # ãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹ã‚’å–å¾—
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã®æƒ…å ±ã‚’æŠ½å‡º
            repositories = []
            
            # ãƒªãƒã‚¸ãƒˆãƒªã®ã‚³ãƒ³ãƒ†ãƒŠã‚’æ¤œç´¢
            repo_containers = soup.find_all('article', class_='Box-row')
            
            for container in repo_containers[:20]:  # ä¸Šä½20ä»¶ã‚’å–å¾—
                try:
                    repo_data = self._extract_repository_data(container)
                    if repo_data:
                        repositories.append(repo_data)
                        
                except Exception as e:
                    logger.warning(f"ãƒªãƒã‚¸ãƒˆãƒªãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            # DataFrameã«å¤‰æ›
            df = pd.DataFrame(repositories)
            
            logger.info(f"ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df)}ä»¶")
            return df
            
        except Exception as e:
            logger.error(f"GitHubãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _extract_repository_data(self, container):
        """
        ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ãƒŠã‹ã‚‰å€‹åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹
        
        Args:
            container: BeautifulSoupã®è¦ç´ 
            
        Returns:
            dict: ãƒªãƒã‚¸ãƒˆãƒªãƒ‡ãƒ¼ã‚¿
        """
        try:
            # ãƒªãƒã‚¸ãƒˆãƒªåã¨URL
            title_element = container.find('h2', class_='h3')
            if not title_element:
                return None
            
            repo_link = title_element.find('a')
            if not repo_link:
                return None
            
            repo_name = repo_link.get_text(strip=True).replace('\n', '').replace(' ', '')
            repo_url = f"https://github.com{repo_link.get('href', '')}"
            
            # èª¬æ˜Žæ–‡
            description_element = container.find('p', class_='col-9')
            description = description_element.get_text(strip=True) if description_element else ""
            
            # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªž
            language_element = container.find('span', {'itemprop': 'programmingLanguage'})
            language = language_element.get_text(strip=True) if language_element else "ä¸æ˜Ž"
            
            # ã‚¹ã‚¿ãƒ¼æ•°
            stars_element = container.find('a', href=lambda x: x and '/stargazers' in x)
            stars = self._extract_number(stars_element.get_text(strip=True)) if stars_element else 0
            
            # ãƒ•ã‚©ãƒ¼ã‚¯æ•°
            forks_element = container.find('a', href=lambda x: x and '/forks' in x)
            forks = self._extract_number(forks_element.get_text(strip=True)) if forks_element else 0
            
            # ä»Šæ—¥ã®ã‚¹ã‚¿ãƒ¼æ•°
            today_stars_element = container.find('span', class_='d-inline-block')
            today_stars = 0
            if today_stars_element:
                today_stars_text = today_stars_element.get_text(strip=True)
                today_stars = self._extract_number(today_stars_text)
            
            return {
                'ãƒªãƒã‚¸ãƒˆãƒªå': repo_name,
                'URL': repo_url,
                'èª¬æ˜Ž': description,
                'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªž': language,
                'ã‚¹ã‚¿ãƒ¼æ•°': stars,
                'ãƒ•ã‚©ãƒ¼ã‚¯æ•°': forks,
                'ä»Šæ—¥ã®ã‚¹ã‚¿ãƒ¼æ•°': today_stars,
                'å–å¾—æ—¥æ™‚': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            logger.warning(f"å€‹åˆ¥ãƒªãƒã‚¸ãƒˆãƒªãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_number(self, text):
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡ºã™ã‚‹ï¼ˆk, M ãªã©ã®å˜ä½ã«å¯¾å¿œï¼‰
        
        Args:
            text (str): æ•°å€¤ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            int: æŠ½å‡ºã•ã‚ŒãŸæ•°å€¤
        """
        try:
            # æ•°å­—ä»¥å¤–ã®æ–‡å­—ã‚’é™¤åŽ»
            import re
            
            # k, M ãªã©ã®å˜ä½ã‚’å‡¦ç†
            text = text.replace(',', '')
            
            if 'k' in text.lower():
                number = float(re.findall(r'[\d.]+', text)[0])
                return int(number * 1000)
            elif 'm' in text.lower():
                number = float(re.findall(r'[\d.]+', text)[0])
                return int(number * 1000000)
            else:
                numbers = re.findall(r'\d+', text)
                return int(numbers[0]) if numbers else 0
                
        except Exception:
            return 0
    
    def close(self):
        """WebDriverã‚’çµ‚äº†ã™ã‚‹"""
        if self.driver:
            self.driver.quit()
            logger.info("WebDriverã‚’çµ‚äº†ã—ã¾ã—ãŸ")


def run_sample_scraping():
    """ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œã™ã‚‹"""
    scraper = None
    
    try:
        print("=" * 60)
        print("GitHubãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œ")
        print("=" * 60)
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
        scraper = GitHubTrendScraper()
        df = scraper.scrape_trending_repositories()
        
        if df.empty:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        print(f"âœ… {len(df)}ä»¶ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ã—ã¾ã—ãŸ")
        
        # ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
        print("\nðŸ“Š å–å¾—ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«:")
        print(df[['ãƒªãƒã‚¸ãƒˆãƒªå', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªž', 'ã‚¹ã‚¿ãƒ¼æ•°', 'ä»Šæ—¥ã®ã‚¹ã‚¿ãƒ¼æ•°']].head())
        
        # Excelå‡ºåŠ›
        print("\nðŸ“ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ã—ã¦ã„ã¾ã™...")
        
        # ã‚µãƒ³ãƒ—ãƒ«ç”¨è¨­å®šã‚’ä½œæˆ
        config = configparser.ConfigParser()
        config['Excel'] = {
            'output_filename': 'github_trends_{timestamp}.xlsx',
            'output_directory': './output'
        }
        
        excel_writer = ExcelWriter(config)
        excel_filepath = excel_writer.write_to_excel(df, sheet_name='GitHubãƒˆãƒ¬ãƒ³ãƒ‰')
        
        if excel_filepath:
            print(f"âœ… Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {excel_filepath}")
        else:
            print("âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # Slacké€šçŸ¥ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
        print("\nðŸ“¢ Slacké€šçŸ¥ã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã„ã¾ã™...")
        
        config['Slack'] = {
            'webhook_url': '',
            'channel': '#general',
            'username': 'GitHub Trend Bot'
        }
        
        notifier = MockSlackNotifier(config)
        
        if notifier.send_success_notification(excel_filepath, len(df)):
            print("âœ… Slacké€šçŸ¥ãƒ†ã‚¹ãƒˆå®Œäº†")
        else:
            print("âŒ Slacké€šçŸ¥ãƒ†ã‚¹ãƒˆå¤±æ•—")
        
        # ã‚µãƒžãƒªãƒ¼æƒ…å ±
        print("\nðŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚µãƒžãƒªãƒ¼:")
        print(f"  - ç·ãƒªãƒã‚¸ãƒˆãƒªæ•°: {len(df)}ä»¶")
        print(f"  - æœ€ã‚‚äººæ°—ã®è¨€èªž: {df['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªž'].mode().iloc[0] if not df.empty else 'ä¸æ˜Ž'}")
        print(f"  - å¹³å‡ã‚¹ã‚¿ãƒ¼æ•°: {df['ã‚¹ã‚¿ãƒ¼æ•°'].mean():.0f}")
        print(f"  - ä»Šæ—¥ã®ç·ã‚¹ã‚¿ãƒ¼æ•°: {df['ä»Šæ—¥ã®ã‚¹ã‚¿ãƒ¼æ•°'].sum()}")
        
        print("\nðŸŽ‰ ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return False
        
    finally:
        if scraper:
            scraper.close()


def test_individual_modules():
    """å€‹åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹"""
    print("=" * 60)
    print("å€‹åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # Excelå‡ºåŠ›ãƒ†ã‚¹ãƒˆ
    print("\n1. Excelå‡ºåŠ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ")
    try:
        from excel_writer import test_excel_writer
        test_excel_writer()
        print("âœ… Excelå‡ºåŠ›ãƒ†ã‚¹ãƒˆå®Œäº†")
    except Exception as e:
        print(f"âŒ Excelå‡ºåŠ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # Slacké€šçŸ¥ãƒ†ã‚¹ãƒˆ
    print("\n2. Slacké€šçŸ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ")
    try:
        from slack_notifier import test_slack_notifier
        test_slack_notifier()
        print("âœ… Slacké€šçŸ¥ãƒ†ã‚¹ãƒˆå®Œäº†")
    except Exception as e:
        print(f"âŒ Slacké€šçŸ¥ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == '--test':
        test_individual_modules()
    else:
        run_sample_scraping()
